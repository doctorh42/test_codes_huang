{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keihan_500_population.net saved successfully.\n",
      "keihan_1000_population.net saved successfully.\n",
      "keihan_5000_population.net saved successfully.\n",
      "keihan_10000_population.net saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from graph_tool.all import Graph\n",
    "import python_codes.files_operators as fo\n",
    "\n",
    "def read_csv_without_pandas(file_path):\n",
    "    \"\"\"\n",
    "    Read a CSV file and return data as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = [row for row in reader]\n",
    "    return data\n",
    "\n",
    "def sort_and_select_top(data, key, top_n):\n",
    "    \"\"\"\n",
    "    Sort data by a specific key in descending order and return the top N items.\n",
    "    \"\"\"\n",
    "    sorted_data = sorted(data, key=lambda x: int(x[key]), reverse=True)  # Descending order\n",
    "    return sorted_data[:top_n]\n",
    "\n",
    "def create_net_from_population(data, output_file):\n",
    "    \"\"\"\n",
    "    Create a .net file from the given population data.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list): List of dictionaries with x, y, and jinkou keys.\n",
    "        output_file (str): Path to save the .net file.\n",
    "    \"\"\"\n",
    "    # Create a graph\n",
    "    graph = Graph(directed=False)\n",
    "    graph.add_vertex(len(data))  # Add vertices\n",
    "    positions = graph.new_vertex_property(\"vector<double>\")\n",
    "    populations = graph.new_vertex_property(\"int\")\n",
    "    numbers = graph.new_vertex_property(\"int\")  # Add 'number' property\n",
    "    \n",
    "    # Set positions, populations, and numbers\n",
    "    for idx, row in enumerate(data):\n",
    "        positions[graph.vertex(idx)] = (float(row['center_x']), float(row['center_y']))\n",
    "        populations[graph.vertex(idx)] = int(row['jinkou'])\n",
    "        numbers[graph.vertex(idx)] = idx + 1  # Assign a unique number to each vertex\n",
    "    \n",
    "    # Assign properties to the graph\n",
    "    graph.vertex_properties['population'] = populations\n",
    "    graph.vertex_properties['number'] = numbers  # Add 'number' property explicitly\n",
    "    \n",
    "    # Save the graph to a .net file\n",
    "    fo.save_files(output_file, graph, positions, position_flag=True, jinkou_flag=True)\n",
    "    print(f\"{output_file} saved successfully.\")\n",
    "\n",
    "# File paths and processing\n",
    "csv_file_path = '../jinkou_data/plan_A/keihan/5235_global_located.csv'  # Update to your local path\n",
    "data = read_csv_without_pandas(csv_file_path)\n",
    "\n",
    "# Generate .net files for top 484 and 1024 population nodes\n",
    "top_500_data = sort_and_select_top(data, 'jinkou', 500)\n",
    "top_1000_data = sort_and_select_top(data, 'jinkou', 1000)\n",
    "top_5000_data = sort_and_select_top(data, 'jinkou', 5000)\n",
    "top_10000_data = sort_and_select_top(data, 'jinkou', 10000)\n",
    "\n",
    "create_net_from_population(top_500_data, 'keihan_500_population.net')\n",
    "create_net_from_population(top_1000_data, 'keihan_1000_population.net')\n",
    "create_net_from_population(top_5000_data, 'keihan_5000_population.net')\n",
    "create_net_from_population(top_10000_data, 'keihan_10000_population.net')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T07:31:19.793963Z",
     "start_time": "2025-01-15T07:31:19.517744Z"
    }
   },
   "id": "7114f87f3b97cb8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo_500_population.net saved successfully.\n",
      "tokyo_1000_population.net saved successfully.\n",
      "tokyo_5000_population.net saved successfully.\n",
      "tokyo_10000_population.net saved successfully.\n",
      "tokyo_30000_population.net saved successfully.\n",
      "tokyo_50000_population.net saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from graph_tool.all import Graph\n",
    "import python_codes.files_operators as fo\n",
    "\n",
    "def read_csv_without_pandas(file_path):\n",
    "    \"\"\"\n",
    "    Read a CSV file and return data as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = [row for row in reader]\n",
    "    return data\n",
    "\n",
    "def merge_csv_files(file_paths):\n",
    "    \"\"\"\n",
    "    Merge multiple CSV files into a single list of dictionaries.\n",
    "    \"\"\"\n",
    "    merged_data = []\n",
    "    for file_path in file_paths:\n",
    "        merged_data.extend(read_csv_without_pandas(file_path))\n",
    "    return merged_data\n",
    "\n",
    "def sort_and_select_top(data, key, top_n):\n",
    "    \"\"\"\n",
    "    Sort data by a specific key in descending order and return the top N items.\n",
    "    \"\"\"\n",
    "    sorted_data = sorted(data, key=lambda x: int(x[key]), reverse=True)\n",
    "    return sorted_data[:top_n]\n",
    "\n",
    "def create_net_from_population(data, output_file):\n",
    "    \"\"\"\n",
    "    Create a .net file from the given population data.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list): List of dictionaries with x, y, and jinkou keys.\n",
    "        output_file (str): Path to save the .net file.\n",
    "    \"\"\"\n",
    "    # Create a graph\n",
    "    graph = Graph(directed=False)\n",
    "    graph.add_vertex(len(data))  # Add vertices\n",
    "    positions = graph.new_vertex_property(\"vector<double>\")\n",
    "    populations = graph.new_vertex_property(\"int\")\n",
    "    numbers = graph.new_vertex_property(\"int\")  # Add 'number' property\n",
    "    \n",
    "    # Set positions, populations, and numbers\n",
    "    for idx, row in enumerate(data):\n",
    "        positions[graph.vertex(idx)] = (float(row['center_x']), float(row['center_y']))\n",
    "        populations[graph.vertex(idx)] = int(row['jinkou'])\n",
    "        numbers[graph.vertex(idx)] = idx + 1  # Assign a unique number to each vertex\n",
    "    \n",
    "    # Assign properties to the graph\n",
    "    graph.vertex_properties['population'] = populations\n",
    "    graph.vertex_properties['number'] = numbers  # Add 'number' property explicitly\n",
    "    \n",
    "    # Save the graph to a .net file\n",
    "    fo.save_files(output_file, graph, positions, position_flag=True, jinkou_flag=True)\n",
    "    print(f\"{output_file} saved successfully.\")\n",
    "\n",
    "# Paths to CSV files\n",
    "csv_files = [\n",
    "    '../jinkou_data/plan_A/tokyo/5239_global_located.csv',\n",
    "    '../jinkou_data/plan_A/tokyo/5240_global_located.csv',\n",
    "    '../jinkou_data/plan_A/tokyo/5339_global_located.csv',\n",
    "    '../jinkou_data/plan_A/tokyo/5340_global_located.csv'\n",
    "]\n",
    "\n",
    "# Merge data from all CSV files\n",
    "merged_data = merge_csv_files(csv_files)\n",
    "\n",
    "# Generate a single .net file for the top 484 nodes across all files\n",
    "top_500_data = sort_and_select_top(merged_data, 'jinkou', 500)\n",
    "top_1000_data = sort_and_select_top(merged_data, 'jinkou', 1000)\n",
    "top_5000_data = sort_and_select_top(merged_data, 'jinkou', 5000)\n",
    "top_10000_data = sort_and_select_top(merged_data, 'jinkou', 10000)\n",
    "top_30000_data = sort_and_select_top(merged_data, 'jinkou', 30000)\n",
    "top_50000_data = sort_and_select_top(merged_data, 'jinkou', 50000)\n",
    "\n",
    "create_net_from_population(top_500_data, 'tokyo_500_population.net')\n",
    "create_net_from_population(top_1000_data, 'tokyo_1000_population.net')\n",
    "create_net_from_population(top_5000_data, 'tokyo_5000_population.net')\n",
    "create_net_from_population(top_10000_data, 'tokyo_10000_population.net')\n",
    "create_net_from_population(top_30000_data, 'tokyo_30000_population.net')\n",
    "create_net_from_population(top_50000_data, 'tokyo_50000_population.net')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T01:08:02.024852Z",
     "start_time": "2025-03-18T01:07:58.852226Z"
    }
   },
   "id": "d5609db0862e9c30",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2keihan2_500_population.net saved successfully.\n",
      "2keihan2_1000_population.net saved successfully.\n",
      "2keihan2_5000_population.net saved successfully.\n",
      "2keihan2_10000_population.net saved successfully.\n",
      "2keihan2_30000_population.net saved successfully.\n",
      "2keihan2_50000_population.net saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from graph_tool.all import Graph\n",
    "import python_codes.files_operators as fo\n",
    "\n",
    "\n",
    "def read_csv_without_pandas(file_path):\n",
    "    \"\"\"\n",
    "    Read a CSV file and return data as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = [row for row in reader]\n",
    "    return data\n",
    "\n",
    "\n",
    "def merge_csv_files(file_paths):\n",
    "    \"\"\"\n",
    "    Merge multiple CSV files into a single list of dictionaries.\n",
    "    \"\"\"\n",
    "    merged_data = []\n",
    "    for file_path in file_paths:\n",
    "        merged_data.extend(read_csv_without_pandas(file_path))\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "def sort_and_select_top(data, key, top_n):\n",
    "    \"\"\"\n",
    "    Sort data by a specific key in descending order and return the top N items.\n",
    "    \"\"\"\n",
    "    sorted_data = sorted(data, key=lambda x: int(x[key]), reverse=True)\n",
    "    return sorted_data[:top_n]\n",
    "\n",
    "\n",
    "def create_net_from_population(data, output_file):\n",
    "    \"\"\"\n",
    "    Create a .net file from the given population data.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list): List of dictionaries with x, y, and jinkou keys.\n",
    "        output_file (str): Path to save the .net file.\n",
    "    \"\"\"\n",
    "    # Create a graph\n",
    "    graph = Graph(directed=False)\n",
    "    graph.add_vertex(len(data))  # Add vertices\n",
    "    positions = graph.new_vertex_property(\"vector<double>\")\n",
    "    populations = graph.new_vertex_property(\"int\")\n",
    "    numbers = graph.new_vertex_property(\"int\")  # Add 'number' property\n",
    "\n",
    "    # Set positions, populations, and numbers\n",
    "    for idx, row in enumerate(data):\n",
    "        positions[graph.vertex(idx)] = (float(row['center_x']), float(row['center_y']))\n",
    "        populations[graph.vertex(idx)] = int(row['jinkou'])\n",
    "        numbers[graph.vertex(idx)] = idx + 1  # Assign a unique number to each vertex\n",
    "\n",
    "    # Assign properties to the graph\n",
    "    graph.vertex_properties['population'] = populations\n",
    "    graph.vertex_properties['number'] = numbers  # Add 'number' property explicitly\n",
    "\n",
    "    # Save the graph to a .net file\n",
    "    fo.save_files(output_file, graph, positions, position_flag=True, jinkou_flag=True)\n",
    "    print(f\"{output_file} saved successfully.\")\n",
    "\n",
    "\n",
    "# Paths to CSV files\n",
    "csv_files = [\n",
    "    '../jinkou_data/plan_B/keihan/5135_global_located.csv',\n",
    "    '../jinkou_data/plan_B/keihan/5235_global_located.csv',\n",
    "]\n",
    "\n",
    "# Merge data from all CSV files\n",
    "merged_data = merge_csv_files(csv_files)\n",
    "\n",
    "# Generate a single .net file for the top 484 nodes across all files\n",
    "top_500_data = sort_and_select_top(merged_data, 'jinkou', 500)\n",
    "top_1000_data = sort_and_select_top(merged_data, 'jinkou', 1000)\n",
    "top_5000_data = sort_and_select_top(merged_data, 'jinkou', 5000)\n",
    "top_10000_data = sort_and_select_top(merged_data, 'jinkou', 10000)\n",
    "top_30000_data = sort_and_select_top(merged_data, 'jinkou', 30000)\n",
    "top_50000_data = sort_and_select_top(merged_data, 'jinkou', 50000)\n",
    "\n",
    "create_net_from_population(top_500_data, '2keihan2_500_population.net')\n",
    "create_net_from_population(top_1000_data, '2keihan2_1000_population.net')\n",
    "create_net_from_population(top_5000_data, '2keihan2_5000_population.net')\n",
    "create_net_from_population(top_10000_data, '2keihan2_10000_population.net')\n",
    "create_net_from_population(top_30000_data, '2keihan2_30000_population.net')\n",
    "create_net_from_population(top_50000_data, '2keihan2_50000_population.net')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T01:10:52.543551Z",
     "start_time": "2025-03-18T01:10:51.784753Z"
    }
   },
   "id": "5500025c5cd38da7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a463b2ffdb08955a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
