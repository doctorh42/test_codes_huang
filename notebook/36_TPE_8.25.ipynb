{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes:  39 links  61\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 201\u001B[0m\n\u001B[1;32m    197\u001B[0m mutation_probs \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.075\u001B[39m, \u001B[38;5;241m0.15\u001B[39m, \u001B[38;5;241m0.3\u001B[39m]\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# 初始化进度条\u001B[39;00m\n\u001B[1;32m    200\u001B[0m progress_bars \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m--> 201\u001B[0m     pop_size: \u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mPopulation=\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mpop_size\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mposition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mleave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, pop_size \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(population_sizes)\n\u001B[1;32m    203\u001B[0m }\n\u001B[1;32m    205\u001B[0m \u001B[38;5;66;03m# 用于存储所有图表的最小和最大适应度值，用于后续统一设置y轴范围\u001B[39;00m\n\u001B[1;32m    206\u001B[0m all_min_values \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/anaconda3/envs/gt/lib/python3.12/site-packages/tqdm/std.py:665\u001B[0m, in \u001B[0;36mtqdm.__new__\u001B[0;34m(cls, *_, **__)\u001B[0m\n\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;241m*\u001B[39m_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m__):\n\u001B[1;32m    664\u001B[0m     instance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m--> 665\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# also constructs lock if non-existent\u001B[39;49;00m\n\u001B[1;32m    666\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_instances\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstance\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    667\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# create monitoring thread\u001B[39;49;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/gt/lib/python3.12/site-packages/tqdm/std.py:111\u001B[0m, in \u001B[0;36mTqdmDefaultWriteLock.__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__enter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 111\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gt/lib/python3.12/site-packages/tqdm/std.py:104\u001B[0m, in \u001B[0;36mTqdmDefaultWriteLock.acquire\u001B[0;34m(self, *a, **k)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21macquire\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mk):\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m lock \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocks:\n\u001B[0;32m--> 104\u001B[0m         \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from graph_tool.all import Graph, shortest_distance, graph_draw\n",
    "from deap import base, creator, tools, algorithms\n",
    "import python_codes.files_operators as fo\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from fractions import Fraction\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle  # 用于保存和读取文件\n",
    "import os\n",
    "\n",
    "# 读取图和位置信息\n",
    "filename1 = \"Janos-us-ca_Norm\"\n",
    "read_graph, read_pos = fo.read_files(f\"../networks_clusters/{filename1}.net\")\n",
    "num_edges = read_graph.num_edges()\n",
    "print(\"nodes: \", read_graph.num_vertices(), \"links \", num_edges)\n",
    "\n",
    "# 计算并添加边的欧氏距离作为权重属性\n",
    "edge_weights = read_graph.new_edge_property(\"double\")\n",
    "for edge in read_graph.edges():\n",
    "    source_pos = read_pos[edge.source()]\n",
    "    target_pos = read_pos[edge.target()]\n",
    "    euclidean_distance = np.sqrt((source_pos[0] - target_pos[0]) ** 2 + (source_pos[1] - target_pos[1]) ** 2)\n",
    "    edge_weights[edge] = euclidean_distance\n",
    "\n",
    "# 将图转换为个体编码\n",
    "def graph_to_individual(graph):\n",
    "    num_vertices = graph.num_vertices()\n",
    "    individual = [0] * (num_vertices * num_vertices)\n",
    "    for edge in graph.edges():\n",
    "        source, target = int(edge.source()), int(edge.target())\n",
    "        individual[source * num_vertices + target] = 1\n",
    "        individual[target * num_vertices + source] = 1\n",
    "    return individual\n",
    "\n",
    "# 将个体解码为图并计算边权重属性\n",
    "def individual_to_graph(individual, num_vertices):\n",
    "    graph = Graph(directed=False)\n",
    "    graph.add_vertex(num_vertices)\n",
    "    new_edge_weights = graph.new_edge_property(\"double\")\n",
    "    for i in range(num_vertices):\n",
    "        for j in range(i + 1, num_vertices):\n",
    "            if individual[i * num_vertices + j] == 1:\n",
    "                edge = graph.add_edge(graph.vertex(i), graph.vertex(j))\n",
    "                source_pos = read_pos[graph.vertex(i)]\n",
    "                target_pos = read_pos[graph.vertex(j)]\n",
    "                euclidean_distance = np.sqrt(\n",
    "                    (source_pos[0] - target_pos[0]) ** 2 + (source_pos[1] - target_pos[1]) ** 2)\n",
    "                new_edge_weights[edge] = euclidean_distance\n",
    "    return graph, new_edge_weights\n",
    "\n",
    "# 定义适应度函数\n",
    "def evaluate(individual):\n",
    "    graph, new_edge_weights = individual_to_graph(individual, read_graph.num_vertices())\n",
    "    num_edges = graph.num_edges()\n",
    "    if num_edges != read_graph.num_edges():  # 边数限制，确保边数为文件中边的数量\n",
    "        return float('inf'),  # 如果边数不为文件中边的数量，适应度设为无穷大\n",
    "    dist_matrix = shortest_distance(graph, weights=new_edge_weights).get_2d_array(range(graph.num_vertices()))\n",
    "    total_distance = np.sum(dist_matrix[dist_matrix != np.inf])\n",
    "    return total_distance,\n",
    "\n",
    "# 自定义交叉操作\n",
    "def cxGraph(ind1, ind2):\n",
    "    size = len(ind1)\n",
    "    point = random.randint(1, size - 1)\n",
    "    new_ind1 = creator.Individual(np.concatenate((ind1[:point], ind2[point:])))\n",
    "    new_ind2 = creator.Individual(np.concatenate((ind2[:point], ind1[point:])))\n",
    "\n",
    "    # 修正边数\n",
    "    def fix_edges(individual):\n",
    "        num_vertices = int(np.sqrt(len(individual)))\n",
    "        edges = [(i, j) for i in range(num_vertices) for j in range(i + 1, num_vertices) if\n",
    "                 individual[i * num_vertices + j] == 1]\n",
    "        non_edges = [(i, j) for i in range(num_vertices) for j in range(i + 1, num_vertices) if\n",
    "                     individual[i * num_vertices + j] == 0]\n",
    "        if len(edges) > num_edges:\n",
    "            # 移除多余的边\n",
    "            extra_edges = random.sample(edges, len(edges) - num_edges)\n",
    "            for i, j in extra_edges:\n",
    "                individual[i * num_vertices + j] = 0\n",
    "                individual[j * num_vertices + i] = 0\n",
    "        elif len(edges) < num_edges:\n",
    "            # 添加缺失的边\n",
    "            missing_edges = random.sample(non_edges, num_edges - len(edges))\n",
    "            for i, j in missing_edges:\n",
    "                individual[i * num_vertices + j] = 1\n",
    "                individual[j * num_vertices + i] = 1\n",
    "        return individual\n",
    "\n",
    "    new_ind1 = fix_edges(new_ind1)\n",
    "    new_ind2 = fix_edges(new_ind2)\n",
    "\n",
    "    return new_ind1, new_ind2\n",
    "\n",
    "# 自定义变异操作\n",
    "def mutGraph(ind):\n",
    "    size = int(np.sqrt(len(ind)))\n",
    "    edges = [(i, j) for i in range(size) for j in range(i + 1, size) if ind[i * size + j] == 1]\n",
    "    non_edges = [(i, j) for i in range(size) for j in range(i + 1, size) if ind[i * size + j] == 0]\n",
    "\n",
    "    if edges and non_edges:\n",
    "        # 移除一条边\n",
    "        i, j = random.choice(edges)\n",
    "        ind[i * size + j] = 0\n",
    "        ind[j * size + i] = 0\n",
    "\n",
    "        # 添加一条边\n",
    "        i, j = random.choice(non_edges)\n",
    "        ind[i * size + j] = 1\n",
    "        ind[j * size + i] = 1\n",
    "\n",
    "    return ind,\n",
    "\n",
    "# 遗传算法设置\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "\n",
    "# 初始化个体时确保边数为文件中的边数量\n",
    "def initIndividual():\n",
    "    num_vertices = read_graph.num_vertices()\n",
    "    individual = [0] * (num_vertices * num_vertices)\n",
    "    edges = random.sample([(i, j) for i in range(num_vertices) for j in range(i + 1, num_vertices)], num_edges)\n",
    "    for i, j in edges:\n",
    "        individual[i * num_vertices + j] = 1\n",
    "        individual[j * num_vertices + i] = 1\n",
    "    return creator.Individual(individual)\n",
    "\n",
    "toolbox.register(\"individual\", initIndividual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", cxGraph)\n",
    "toolbox.register(\"mutate\", mutGraph)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# 保存初始种群\n",
    "def save_population(population, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(population, f)\n",
    "\n",
    "# 读取初始种群\n",
    "def load_population(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# 主遗传算法流程\n",
    "def main(population_size, selection_ratio, mutpb, initial_population, pbar):\n",
    "    num_selected = int(population_size * selection_ratio)\n",
    "    num_offspring = population_size - num_selected\n",
    "    num_generations = 1000  # 设定总迭代次数\n",
    "    cxpb = 0.5  # 交叉概率\n",
    "\n",
    "    # 使用固定的初始种群\n",
    "    pop = initial_population[:]\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"min\", np.min)\n",
    "\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = [\"gen\", \"min\"]\n",
    "\n",
    "    for gen in range(num_generations):\n",
    "        # 选择操作\n",
    "        selected = toolbox.select(pop, num_selected)\n",
    "\n",
    "        # 生成新的个体\n",
    "        offspring = algorithms.varAnd(selected, toolbox, cxpb, mutpb)\n",
    "        offspring = offspring[:num_offspring]\n",
    "\n",
    "        # 组合父代和新生成的个体，形成新的种群\n",
    "        pop[:] = selected + offspring\n",
    "\n",
    "        # 评估新的种群\n",
    "        fitnesses = list(map(toolbox.evaluate, pop))\n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # 记录和输出每一代的最优适应度值\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, **record)\n",
    "\n",
    "        # 更新进度条\n",
    "        pbar.update(1)\n",
    "\n",
    "        # 更新Hall of Fame\n",
    "        hof.update(pop)\n",
    "\n",
    "    return logbook, hof\n",
    "\n",
    "# 配置参数\n",
    "population_sizes = [75, 150, 300]\n",
    "selection_ratios = [1 / 3, 1 / 2, 2 / 3, 3 / 4]\n",
    "mutation_probs = [0.075, 0.15, 0.3]\n",
    "\n",
    "# 初始化进度条\n",
    "progress_bars = {\n",
    "    pop_size: tqdm(total=12 * 1000, desc=f'Population={pop_size}', position=i, leave=True)\n",
    "    for i, pop_size in enumerate(population_sizes)\n",
    "}\n",
    "\n",
    "# 用于存储所有图表的最小和最大适应度值，用于后续统一设置y轴范围\n",
    "all_min_values = []\n",
    "all_max_values = []\n",
    "initial_fitness_values = {}  # 用于存储初始适应度值\n",
    "\n",
    "# 逐个运行每个种群大小的12种情况\n",
    "for population_size in population_sizes:\n",
    "    population_filename = f\"./output_TPE/initial_population_{filename1}_{population_size}.pkl\"\n",
    "\n",
    "    # 检查是否已有保存的初始种群文件\n",
    "    if os.path.exists(population_filename):\n",
    "        initial_population = load_population(population_filename)\n",
    "    else:\n",
    "        # 生成并保存初始种群\n",
    "        initial_population = toolbox.population(n=population_size)\n",
    "        save_population(initial_population, population_filename)\n",
    "\n",
    "    # 评估初始种群的适应度\n",
    "    fitnesses = list(map(toolbox.evaluate, initial_population))\n",
    "    initial_fitness = min(fitnesses)[0]  # 记录最小适应度\n",
    "    initial_fitness_values[population_size] = initial_fitness\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_params = {\n",
    "            executor.submit(main, population_size, selection_ratio, mutpb, initial_population, progress_bars[population_size]): (\n",
    "                selection_ratio, mutpb)\n",
    "            for selection_ratio in selection_ratios\n",
    "            for mutpb in mutation_probs\n",
    "        }\n",
    "\n",
    "        logbooks = {}\n",
    "        labels = {}\n",
    "\n",
    "        for future in as_completed(future_to_params):\n",
    "            selection_ratio, mutpb = future_to_params[future]\n",
    "            try:\n",
    "                logbook, _ = future.result()\n",
    "                logbooks[(selection_ratio, mutpb)] = logbook\n",
    "                ratio_fraction = Fraction(selection_ratio).limit_denominator()\n",
    "                labels[(selection_ratio, mutpb)] = f'Select={ratio_fraction}, Mutate={mutpb * 100}%'\n",
    "\n",
    "                # 更新最小和最大适应度值\n",
    "                min_fitness_values = logbook.select(\"min\")\n",
    "                all_min_values.append(min(min_fitness_values))\n",
    "                all_max_values.append(max(min_fitness_values))\n",
    "\n",
    "            except Exception as ex:\n",
    "                print(\n",
    "                    f'Error with population_size={population_size}, selection_ratio={selection_ratio}, mutpb={mutpb}: {ex}')\n",
    "\n",
    "# 确定统一的y轴范围\n",
    "y_min = 0\n",
    "y_max = max(all_max_values)\n",
    "\n",
    "# 重新绘制图表，确保y轴范围一致，并添加初始适应度值作为x=0点\n",
    "for population_size in population_sizes:\n",
    "    plt.figure(figsize=(14, 1000))\n",
    "    for (selection_ratio, mutpb), logbook in logbooks.items():\n",
    "        min_fitness_values = logbook.select(\"min\")\n",
    "        generations = list(range(1, len(min_fitness_values) + 1))\n",
    "        fitness_values = [initial_fitness_values[population_size]] + min_fitness_values  # 添加初始适应度值\n",
    "        generations = [0] + generations  # x轴从0开始\n",
    "\n",
    "        plt.plot(generations, fitness_values, label=labels[(selection_ratio, mutpb)])\n",
    "\n",
    "    plt.title(f\"Fitness Value over Generations (Population Size = {population_size})\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness Value (Cost)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 设置统一的y轴范围\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    # 保存图表\n",
    "    plt.savefig(f\"./output_TPE/{filename1}_fitness_over_generations_population_{population_size}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# 完成后关闭所有进度条\n",
    "for pbar in progress_bars.values():\n",
    "    pbar.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T13:08:11.939345Z",
     "start_time": "2024-08-25T13:08:01.789891Z"
    }
   },
   "id": "6e3d216dc7048899",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e9e52796effc222"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
